{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97555,"databundleVersionId":11670858,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:33:09.121272Z","iopub.execute_input":"2025-04-21T05:33:09.12175Z","iopub.status.idle":"2025-04-21T05:33:09.377917Z","shell.execute_reply.started":"2025-04-21T05:33:09.121726Z","shell.execute_reply":"2025-04-21T05:33:09.377142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import median_filter, percentile_filter\nimport os\n\n# List of image paths (replace with your actual image paths)\nspad_image_paths = [\n '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/testing-images/10052011.png',    # Example: original SPAD image path\n '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/testing-images/10052012.png'       # Another SPAD image path\n]\n\ndef show_median_filtered(spad_paths, filter_size=7):\n    n = len(spad_paths)\n    plt.figure(figsize=(8, 4 * n))\n    for i, path in enumerate(spad_paths):\n        # Load as grayscale\n        spad_img = Image.open(path).convert('L')\n        spad_np = np.array(spad_img)\n        # Apply median filter\n        filtered = median_filter(spad_np, size=filter_size)\n        filtered_img = percentile_filter(spad_img, percentile=80, size=5)\n        # Plot original\n        plt.subplot(n, 2, 2*i+1)\n        plt.imshow(spad_np, cmap='gray')\n        plt.title(f'Original SPAD Image\\n{os.path.basename(path)}')\n        plt.axis('off')\n        # Plot filtered\n        plt.subplot(n, 2, 2*i+2)\n        plt.imshow(filtered_img, cmap='gray')\n        plt.title(f'Median Filtered (size={filter_size})')\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Call the function\nshow_median_filtered(spad_image_paths, filter_size=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:33:09.379083Z","iopub.execute_input":"2025-04-21T05:33:09.379387Z","execution_failed":"2025-04-21T06:09:51.434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport numpy as np\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom scipy.ndimage import median_filter, percentile_filter\n\n# Clear GPU cache before starting\ntorch.cuda.empty_cache()\n\nclass CoarseNetwork(nn.Module):\n    def __init__(self):\n        super(CoarseNetwork, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(64, 1, kernel_size=3, padding=1)\n        )\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\nclass FineNetwork(nn.Module):\n    def __init__(self):\n        super(FineNetwork, self).__init__()\n        self.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=1, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        \n        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2)\n        self.bn2 = nn.BatchNorm2d(64)\n        \n        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(32)\n        \n        self.conv4 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n        self.bn4 = nn.BatchNorm2d(16)\n        \n        self.conv5 = nn.Conv2d(16, 1, kernel_size=1)\n        \n    def forward(self, img, coarse_depth):\n        if coarse_depth.shape != img.shape:\n            coarse_depth = nn.functional.interpolate(\n                coarse_depth, size=img.shape[2:], mode='bilinear', align_corners=False)\n        \n        x = torch.cat([img, coarse_depth], dim=1)\n        \n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.relu(self.bn3(self.conv3(x)))\n        x = self.relu(self.bn4(self.conv4(x)))\n        \n        fine_depth = self.conv5(x) + coarse_depth\n        \n        return fine_depth\n\nclass MultiScaleDepthNetwork(nn.Module):\n    def __init__(self):\n        super(MultiScaleDepthNetwork, self).__init__()\n        self.coarse_network = CoarseNetwork()\n        self.fine_network = FineNetwork()\n        \n    def forward(self, x):\n        coarse_depth = self.coarse_network(x)\n        fine_depth = self.fine_network(x, coarse_depth)\n        return fine_depth\n\nclass SPADDataset(Dataset):\n    def __init__(self, spad_dir, depth_dir, transform=None):\n        self.spad_dir = spad_dir\n        self.depth_dir = depth_dir\n        self.transform = transform\n        self.spad_files = sorted([f for f in os.listdir(spad_dir) if f.endswith('.png')])\n        \n    def __len__(self):\n        return len(self.spad_files)\n    \n    def __getitem__(self, idx):\n        spad_path = os.path.join(self.spad_dir, self.spad_files[idx])\n        depth_path = os.path.join(self.depth_dir, self.spad_files[idx])\n        \n        spad_img = Image.open(spad_path).convert('L')\n        spad_np = np.array(spad_img)\n        filtered_spad = percentile_filter(spad_np, percentile=80, size=3)\n        spad_img = Image.fromarray(filtered_spad.astype(np.uint8))\n        depth_img = Image.open(depth_path).convert('L')\n        \n        if self.transform:\n            spad_img = self.transform(spad_img)\n            depth_img = self.transform(depth_img)\n        \n        return spad_img, depth_img\n\nclass TestSPADDataset(Dataset):\n    def __init__(self, spad_dir, transform=None):\n        self.spad_dir = spad_dir\n        self.transform = transform\n        self.spad_files = sorted([f for f in os.listdir(spad_dir) if f.endswith('.png')])\n        \n    def __len__(self):\n        return len(self.spad_files)\n    \n    def __getitem__(self, idx):\n        spad_path = os.path.join(self.spad_dir, self.spad_files[idx])\n        spad_img = Image.open(spad_path).convert('L')\n        spad_np = np.array(spad_img)\n        filtered_spad = percentile_filter(spad_np, percentile=80, size=3)\n        spad_img = Image.fromarray(filtered_spad.astype(np.uint8))\n        \n        if self.transform:\n            spad_img = self.transform(spad_img)\n        \n        return spad_img, self.spad_files[idx]\n\ndef combined_loss(pred, target, alpha=0.4, beta=0.6):\n    mse_loss = nn.MSELoss()(pred, target)\n    mae_loss = nn.L1Loss()(pred, target)\n    return alpha * mse_loss + beta * mae_loss\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, device='cuda'):\n    model.to(device)\n    best_val_loss = float('inf')\n    patience = 5\n    patience_counter = 0\n    \n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n        \n        for spad_imgs, depth_maps in train_pbar:\n            spad_imgs = spad_imgs.to(device)\n            depth_maps = depth_maps.to(device)\n            \n            outputs = model(spad_imgs)\n            loss = criterion(outputs, depth_maps)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            train_pbar.set_postfix({'loss': loss.item()})\n        \n        avg_train_loss = train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        \n        model.eval()\n        val_loss = 0.0\n        \n        val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n        \n        with torch.no_grad():\n            for spad_imgs, depth_maps in val_pbar:\n                spad_imgs = spad_imgs.to(device)\n                depth_maps = depth_maps.to(device)\n                \n                outputs = model(spad_imgs)\n                loss = criterion(outputs, depth_maps)\n                \n                val_loss += loss.item()\n                val_pbar.set_postfix({'loss': loss.item()})\n        \n        avg_val_loss = val_loss / len(val_loader)\n        val_losses.append(avg_val_loss)\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n        \n        scheduler.step(avg_val_loss)\n        \n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), 'best_spad_depth_model.pth')\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            \n        if patience_counter >= patience:\n            print(f'Early stopping after {epoch+1} epochs')\n            break\n    \n    plot_loss(train_losses, val_losses, train_loader.batch_size, optimizer.param_groups[0]['lr'])\n    \n    return model, train_losses, val_losses\n\ndef plot_loss(train_losses, val_losses, batch_size, learning_rate):\n    epochs = len(train_losses)\n    plt.figure(figsize=(10, 6))\n    plt.plot(range(1, epochs + 1), train_losses, label='Train Loss', marker='o')\n    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss', marker='x')\n    plt.title(f'Training and Validation Loss\\nBatch Size: {batch_size}, Learning Rate: {learning_rate}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig('loss_plot.png')\n    plt.show()\n\ndef generate_predictions(model, test_loader, output_dir, device='cuda'):\n    model.eval()\n    os.makedirs(output_dir, exist_ok=True)\n    \n    test_pbar = tqdm(test_loader, desc='Generating predictions')\n    \n    with torch.no_grad():\n        for spad_imgs, filenames in test_pbar:\n            spad_imgs = spad_imgs.to(device)\n            outputs = model(spad_imgs)\n            \n            for j, output in enumerate(outputs):\n                depth_map = output.cpu().numpy().squeeze()\n                depth_map = ((depth_map - depth_map.min()) / (depth_map.max() - depth_map.min()) * 255).astype(np.uint8)\n                \n                img = Image.fromarray(depth_map)\n                img.save(os.path.join(output_dir, filenames[j]))\n\ndef main():\n    train_spad_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/training-images'\n    train_depth_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/training-depths'\n    val_spad_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/validation-images'\n    val_depth_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/validation-depths'\n    test_spad_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/testing-images'\n    output_dir = '/kaggle/working/multiscaleMODEL_batch32_epoch6_L1loss'\n    \n    batch_size = 32\n    learning_rate = 0.0002\n    num_epochs = 4\n    \n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n    ])\n    \n    train_dataset = SPADDataset(train_spad_dir, train_depth_dir, transform=transform)\n    val_dataset = SPADDataset(val_spad_dir, val_depth_dir, transform=transform)\n    test_dataset = TestSPADDataset(test_spad_dir, transform=transform)\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n    \n    model = MultiScaleDepthNetwork()\n    criterion = combined_loss\n    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model, train_losses, val_losses = train_model(\n        model, train_loader, val_loader, criterion, optimizer, num_epochs, device\n    )\n    \n    generate_predictions(model, test_loader, output_dir, device)\n    \n    print(\"Training and prediction completed!\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.execute_input":"2025-04-21T05:33:10.099644Z","iopub.status.idle":"2025-04-21T05:42:50.750077Z","shell.execute_reply.started":"2025-04-21T05:33:10.099627Z","shell.execute_reply":"2025-04-21T05:42:50.749489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\n\ndef images_to_csv_with_metadata(image_folder, output_csv):\n    # Initialize an empty list to store image data and metadata\n    data = []\n\n    # Loop through all images in the folder\n    for idx, filename in enumerate(sorted(os.listdir(image_folder))):\n        if filename.endswith(\".png\"):\n            filepath = os.path.join(image_folder, filename)\n            # Read the image\n            image = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)\n            image = cv2.resize(image, (128, 128))\n            image = image / 255.\n            image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-6)\n            image = np.uint8(image * 255.)\n            # Flatten the image into a 1D array\n            image_flat = image.flatten()\n            # Add ID, ImageID (filename), and pixel values\n            row = [idx, filename] + image_flat.tolist()\n            data.append(row)\n    \n    # Create a DataFrame\n    num_columns = len(data[0]) - 2 if data else 0\n    column_names = [\"id\", \"ImageID\"] + [indx for indx in range(num_columns)]\n    df = pd.DataFrame(data, columns=column_names)\n\n    # Save to CSV\n    df.to_csv(output_csv, index=False)\n\n# Paths for prediction and ground truth images\npredictions_folder = \"/kaggle/working/multiscaleMODEL_batch32_epoch6_L1loss\"\n\n# Output CSV paths\npredictions_csv = \"predictionsbymultiscalemodel_percentile_80.csv\"\n\n# Convert prediction images to CSV\nimages_to_csv_with_metadata(predictions_folder, predictions_csv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T06:04:09.725853Z","iopub.execute_input":"2025-04-21T06:04:09.726627Z","iopub.status.idle":"2025-04-21T06:04:19.798408Z","shell.execute_reply.started":"2025-04-21T06:04:09.726597Z","shell.execute_reply":"2025-04-21T06:04:19.797858Z"}},"outputs":[],"execution_count":null}]}