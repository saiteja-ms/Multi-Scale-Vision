{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97555,"databundleVersionId":11670858,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:18:51.597595Z","iopub.execute_input":"2025-04-09T13:18:51.597921Z","iopub.status.idle":"2025-04-09T13:18:51.603675Z","shell.execute_reply.started":"2025-04-09T13:18:51.597898Z","shell.execute_reply":"2025-04-09T13:18:51.602800Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport numpy as np\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pandas as pd\n\ntorch.cuda.empty_cache()\n\n# Define a UNet architecture for depth estimation\nclass UNet(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super(UNet, self).__init__()\n        \n        # Encoder\n        self.enc1 = self._block(in_channels, 64)\n        self.enc2 = self._block(64, 128)\n        self.enc3 = self._block(128, 256)\n        self.enc4 = self._block(256, 512)\n        \n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        # Bottleneck\n        self.bottleneck = self._block(512, 1024)\n        \n        # Decoder\n        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n        self.dec4 = self._block(1024, 512)\n        \n        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n        self.dec3 = self._block(512, 256)\n        \n        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.dec2 = self._block(256, 128)\n        \n        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.dec1 = self._block(128, 64)\n        \n        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n        \n    def _block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    \n    def forward(self, x):\n        # Encoder\n        enc1 = self.enc1(x)\n        enc2 = self.enc2(self.pool(enc1))\n        enc3 = self.enc3(self.pool(enc2))\n        enc4 = self.enc4(self.pool(enc3))\n        \n        # Bottleneck\n        bottleneck = self.bottleneck(self.pool(enc4))\n        \n        # Decoder\n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((dec4, enc4), dim=1)\n        dec4 = self.dec4(dec4)\n        \n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.dec3(dec3)\n        \n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.dec2(dec2)\n        \n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.dec1(dec1)\n        \n        return self.final_conv(dec1)\n\n# Custom Dataset for SPAD images and depth maps\nclass SPADDataset(Dataset):\n    def __init__(self, spad_dir, depth_dir, transform=None):\n        self.spad_dir = spad_dir\n        self.depth_dir = depth_dir\n        self.transform = transform\n        self.spad_files = sorted([f for f in os.listdir(spad_dir) if f.endswith('.png')])\n        \n    def __len__(self):\n        return len(self.spad_files)\n    \n    def __getitem__(self, idx):\n        spad_path = os.path.join(self.spad_dir, self.spad_files[idx])\n        depth_path = os.path.join(self.depth_dir, self.spad_files[idx])\n        \n        # Load SPAD image (binary)\n        spad_img = Image.open(spad_path).convert('L')  # Convert to grayscale\n        \n        # Load depth map\n        depth_img = Image.open(depth_path).convert('L')\n        \n        if self.transform:\n            spad_img = self.transform(spad_img)\n            depth_img = self.transform(depth_img)\n        \n        return spad_img, depth_img\n\nclass TestSPADDataset(Dataset):\n    def __init__(self, spad_dir, transform=None):\n        self.spad_dir = spad_dir\n        self.transform = transform\n        self.spad_files = sorted([f for f in os.listdir(spad_dir) if f.endswith('.png')])\n        \n    def __len__(self):\n        return len(self.spad_files)\n    \n    def __getitem__(self, idx):\n        spad_path = os.path.join(self.spad_dir, self.spad_files[idx])\n        \n        # Load SPAD image (binary)\n        spad_img = Image.open(spad_path).convert('L')  # Convert to grayscale\n        \n        if self.transform:\n            spad_img = self.transform(spad_img)\n        \n        # Return the filename as well for saving predictions with correct names\n        return spad_img, self.spad_files[idx]\n        \n# Training function\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n    model.to(device)\n    best_val_loss = float('inf')\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n\n        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n        \n        for spad_imgs, depth_maps in train_pbar:\n            spad_imgs = spad_imgs.to(device)\n            depth_maps = depth_maps.to(device)\n            \n            # Forward pass\n            outputs = model(spad_imgs)\n            loss = criterion(outputs, depth_maps)\n            \n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n\n            train_pbar.set_postfix({'loss': loss.item()})\n        \n        avg_train_loss = train_loss / len(train_loader)\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n\n        val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n        with torch.no_grad():\n            for spad_imgs, depth_maps in val_pbar:\n                spad_imgs = spad_imgs.to(device)\n                depth_maps = depth_maps.to(device)\n                \n                outputs = model(spad_imgs)\n                loss = criterion(outputs, depth_maps)\n                \n                val_loss += loss.item()\n                val_pbar.set_postfix({'loss': loss.item()})\n                \n        avg_val_loss = val_loss / len(val_loader)\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n        \n        # Save the best model\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), 'best_spad_depth_model.pth')\n    \n    return model\n\n# Function to generate predictions for test set\ndef generate_predictions(model, test_loader, output_dir, device='cuda'):\n    model.eval()\n    os.makedirs(output_dir, exist_ok=True)\n    \n    with torch.no_grad():\n        for i, (spad_imgs, _) in enumerate(test_loader):\n            spad_imgs = spad_imgs.to(device)\n            outputs = model(spad_imgs)\n            \n            # Convert to numpy and save\n            for j, output in enumerate(outputs):\n                depth_map = output.cpu().numpy().squeeze()\n                # Normalize to 0-255 for saving as image\n                depth_map = ((depth_map - depth_map.min()) / (depth_map.max() - depth_map.min()) * 255).astype(np.uint8)\n                \n                # Save as image\n                img = Image.fromarray(depth_map)\n                img.save(os.path.join(output_dir, f'pred_{i*test_loader.batch_size+j}.png'))\n\n# Main execution\ndef main():\n    # Paths\n    train_spad_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/training-images'\n    train_depth_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/training-depths'\n    val_spad_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/validation-images'\n    val_depth_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/validation-depths'\n    test_spad_dir = '/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data/testing-images'\n    output_dir = '/kaggle/working/predictions'\n    \n    # Hyperparameters\n    batch_size = 32\n    learning_rate = 0.001\n    num_epochs = 20\n    \n    # Transforms\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n    ])\n    \n    # Datasets and DataLoaders\n    train_dataset = SPADDataset(train_spad_dir, train_depth_dir, transform=transform)\n    val_dataset = SPADDataset(val_spad_dir, val_depth_dir, transform=transform)\n    test_dataset = TestSPADDataset(test_spad_dir, transform=transform)\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n    \n    # Model, loss, and optimizer\n    model = UNet(in_channels=1, out_channels=1)\n    criterion = nn.MSELoss()  # Mean Squared Error loss\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    \n    # Train the model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n    \n    # Generate predictions\n    generate_predictions(model, test_loader, output_dir, device)\n    \n    print(\"Training and prediction completed!\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:02:47.737397Z","iopub.execute_input":"2025-04-29T12:02:47.737678Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/20 [Train]: 100%|██████████| 209/209 [04:17<00:00,  1.23s/it, loss=0.0483]\nEpoch 1/20 [Val]: 100%|██████████| 27/27 [00:18<00:00,  1.47it/s, loss=0.0356]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/20], Train Loss: 0.0657, Val Loss: 0.0538\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20 [Train]: 100%|██████████| 209/209 [03:14<00:00,  1.08it/s, loss=0.0411]\nEpoch 2/20 [Val]: 100%|██████████| 27/27 [00:10<00:00,  2.53it/s, loss=0.0359]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/20], Train Loss: 0.0451, Val Loss: 0.0490\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20 [Train]: 100%|██████████| 209/209 [03:14<00:00,  1.08it/s, loss=0.0505]\nEpoch 3/20 [Val]: 100%|██████████| 27/27 [00:10<00:00,  2.58it/s, loss=0.0348]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/20], Train Loss: 0.0426, Val Loss: 0.0424\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20 [Train]: 100%|██████████| 209/209 [03:13<00:00,  1.08it/s, loss=0.0527]\nEpoch 4/20 [Val]: 100%|██████████| 27/27 [00:10<00:00,  2.61it/s, loss=0.0305]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/20], Train Loss: 0.0397, Val Loss: 0.0430\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20 [Train]:  68%|██████▊   | 143/209 [02:12<01:00,  1.08it/s, loss=0.0362]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\n\ndef images_to_csv_with_metadata(image_folder, output_csv):\n    # Initialize an empty list to store image data and metadata\n    data = []\n\n    # Loop through all images in the folder\n    for idx, filename in enumerate(sorted(os.listdir(image_folder))):\n        if filename.endswith(\".png\"):\n            filepath = os.path.join(image_folder, filename)\n            # Read the image\n            image = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)\n            image = cv2.resize(image, (128, 128))\n            image = image / 255.\n            image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-6)\n            image = np.uint8(image * 255.)\n            # Flatten the image into a 1D array\n            image_flat = image.flatten()\n            # Add ID, ImageID (filename), and pixel values\n            row = [idx, filename] + image_flat.tolist()\n            data.append(row)\n    \n    # Create a DataFrame\n    num_columns = len(data[0]) - 2 if data else 0\n    column_names = [\"id\", \"ImageID\"] + [indx for indx in range(num_columns)]\n    df = pd.DataFrame(data, columns=column_names)\n\n    # Save to CSV\n    df.to_csv(output_csv, index=False)\n\n# Paths for prediction and ground truth images\npredictions_folder = \"/kaggle/working/predictions\"\n\n# Output CSV paths\npredictions_csv = \"/kaggle/working/Final.csv\"\n\n# Convert prediction images to CSV\nimages_to_csv_with_metadata(predictions_folder, predictions_csv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T16:40:04.538104Z","iopub.execute_input":"2025-04-09T16:40:04.538457Z","iopub.status.idle":"2025-04-09T16:40:15.327150Z","shell.execute_reply.started":"2025-04-09T16:40:04.538429Z","shell.execute_reply":"2025-04-09T16:40:15.326480Z"}},"outputs":[],"execution_count":3}]}